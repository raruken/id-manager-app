import streamlit as st
import pandas as pd
import requests
import dropbox
from io import BytesIO, StringIO
try:
    import chardet
    HAS_CHARDET = True
except ImportError:
    HAS_CHARDET = False

# ==============================
# Dropboxæ°¸ç¶šæ¥ç¶šå‡¦ç†
# ==============================
def get_dropbox_access_token():
    data = {
        "grant_type": "refresh_token",
        "refresh_token": st.secrets["DROPBOX_REFRESH_TOKEN"],
        "client_id": st.secrets["DROPBOX_APP_KEY"],
        "client_secret": st.secrets["DROPBOX_APP_SECRET"],
    }
    res = requests.post("https://api.dropboxapi.com/oauth2/token", data=data)
    res.raise_for_status()
    return res.json()["access_token"]

ACCESS_TOKEN = get_dropbox_access_token()
dbx = dropbox.Dropbox(ACCESS_TOKEN)

# ==============================
# è¨­å®š
# ==============================
DROPBOX_FILE_PATH = "/id_management_file.csv"

st.set_page_config(page_title="IDæ¡ç•ªç®¡ç†", layout="wide")
st.title("ğŸ“‹ IDæ¡ç•ªç®¡ç†")
st.caption("åˆ†é…PIDã€åˆ†é…IDã€æ•´å‚™çµæœIDã®å¹´åˆ¥æœ€çµ‚IDã‚’ç·¨é›†ã§ãã¾ã™")

# ==============================
# Dropboxãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¢ç´¢
# ==============================
def validate_path(path):
    """ãƒ‘ã‚¹ãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’æ¤œè¨¼"""
    if path is None:
        return False
    if path == "":
        return True
    if not isinstance(path, str):
        return False
    if not path.startswith("/"):
        return False
    return True

def explore_dropbox_path(path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã‚’å–å¾—"""
    if not validate_path(path):
        return None
    
    if path == "" or path == "/":
        normalized_path = ""
    else:
        normalized_path = path.rstrip("/")
    
    try:
        result = dbx.files_list_folder(normalized_path)
        return result.entries
    except (dropbox.exceptions.BadInputError, dropbox.exceptions.ApiError):
        return None
    except Exception:
        return None

# ==============================
# CSVã®èª­ã¿è¾¼ã¿ï¼ˆShift-JISå¯¾å¿œï¼‰
# ==============================
def load_csv_from_bytes(data, encoding='shift_jis'):
    """ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰CSVã‚’èª­ã¿è¾¼ã‚€ï¼ˆShift-JISå¯¾å¿œï¼‰"""
    try:
        try:
            text_data = data.decode(encoding)
        except UnicodeDecodeError:
            try:
                text_data = data.decode('utf-8')
            except UnicodeDecodeError:
                if HAS_CHARDET:
                    try:
                        detected = chardet.detect(data)
                        encoding = detected['encoding'] if detected['encoding'] else 'utf-8'
                        text_data = data.decode(encoding)
                    except:
                        text_data = data.decode('utf-8', errors='ignore')
                else:
                    text_data = data.decode('utf-8', errors='ignore')
        
        # ã™ã¹ã¦ã®åˆ—ã‚’æ–‡å­—åˆ—ã¨ã—ã¦èª­ã¿è¾¼ã‚€ï¼ˆIDã‚’æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã†ãŸã‚ï¼‰
        df = pd.read_csv(StringIO(text_data), header=0, dtype=str, keep_default_na=False)
        
        if len(df.columns) >= 4:
            df_display = pd.DataFrame({
                'å¹´': df.iloc[:, 0].astype(str),
                'åˆ†é…PID': df.iloc[:, 1].astype(str),
                'åˆ†é…ID': df.iloc[:, 2].astype(str),
                'æ•´å‚™çµæœID': df.iloc[:, 3].astype(str)
            })
        else:
            df_display = df.copy()
            # ã™ã¹ã¦ã®åˆ—ã‚’æ–‡å­—åˆ—å‹ã«çµ±ä¸€
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
        
        return df_display, None, text_data
    except pd.errors.EmptyDataError:
        return pd.DataFrame(), "âŒ **ã‚¨ãƒ©ãƒ¼:** ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™", None
    except pd.errors.ParserError as pe:
        return pd.DataFrame(), f"âŒ **ã‚¨ãƒ©ãƒ¼:** CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ\n**è©³ç´°:** {pe}", None
    except Exception as e:
        return pd.DataFrame(), f"âŒ **ã‚¨ãƒ©ãƒ¼:** ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ\n**è©³ç´°:** {e}", None

def load_csv_from_dropbox(path):
    """Dropboxã‹ã‚‰CSVã‚’èª­ã¿è¾¼ã‚€"""
    try:
        _, res = dbx.files_download(path)
        data = res.content
        df, error_info, text_data = load_csv_from_bytes(data)
        return df, error_info, text_data
    except dropbox.exceptions.ApiError as e:
        error_msg = str(e)
        error_info = ["âŒ **ã‚¨ãƒ©ãƒ¼:** ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"]
        error_info.append(f"**æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹:** `{path}`")
        
        is_not_found = "not_found" in str(e).lower()
        
        if is_not_found:
            path_parts = [p for p in path.split("/") if p]
            if len(path_parts) > 1:
                parent_path = "/" + "/".join(path_parts[:-1])
            else:
                parent_path = ""
            
            if parent_path == "":
                error_info.append(f"\n**è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:** ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºæ–‡å­—åˆ—ï¼‰")
            else:
                error_info.append(f"\n**è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:** `{parent_path}`")
            
            try:
                explore_path = parent_path if parent_path != "" else ""
                entries = explore_dropbox_path(explore_path) if explore_path != "" else dbx.files_list_folder("").entries
                if entries:
                    available_files = []
                    available_folders = []
                    for entry in entries:
                        if isinstance(entry, dropbox.files.FileMetadata):
                            available_files.append(f"ğŸ“„ {entry.name}")
                        elif isinstance(entry, dropbox.files.FolderMetadata):
                            available_folders.append(f"ğŸ“ {entry.name}/")
                    
                    if available_files or available_folders:
                        error_info.append("\n**ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€:**")
                        for folder in available_folders:
                            error_info.append(f"  {folder}")
                        for file in available_files:
                            error_info.append(f"  {file}")
            except Exception as explore_error:
                error_info.append(f"\nâš ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¢ç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {explore_error}")
        
        return pd.DataFrame(), "\n".join(error_info), None

# ==============================
# CSVã®ä¿å­˜
# ==============================
def save_csv_to_dropbox(df, path, original_text=None):
    """Dropboxã«CSVã‚’ä¿å­˜ï¼ˆå…ƒã®CSVæ§‹é€ ã‚’ä¿æŒï¼‰"""
    try:
        if original_text:
            lines = original_text.split('\n')
            for i, row in df.iterrows():
                if i + 1 < len(lines):
                    values = lines[i + 1].split(',')
                    if len(values) >= 4:
                        # IDã‚’æ–‡å­—åˆ—ã¨ã—ã¦ç¢ºå®Ÿã«æ‰±ã†
                        pid_str = str(row['åˆ†é…PID']) if pd.notna(row['åˆ†é…PID']) and str(row['åˆ†é…PID']) != 'nan' else ''
                        id_str = str(row['åˆ†é…ID']) if pd.notna(row['åˆ†é…ID']) and str(row['åˆ†é…ID']) != 'nan' else ''
                        result_id_str = str(row['æ•´å‚™çµæœID']) if pd.notna(row['æ•´å‚™çµæœID']) and str(row['æ•´å‚™çµæœID']) != 'nan' else ''
                        values[1] = pid_str
                        values[2] = id_str
                        values[3] = result_id_str
                        lines[i + 1] = ','.join(values)
            csv_content = '\n'.join(lines)
            csv_bytes = csv_content.encode('shift_jis')
        else:
            # IDåˆ—ãŒæ–‡å­—åˆ—å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰CSVã«å¤‰æ›
            csv_df = df.copy()
            if 'åˆ†é…PID' in csv_df.columns:
                csv_df['åˆ†é…PID'] = csv_df['åˆ†é…PID'].astype(str).replace('nan', '')
            if 'åˆ†é…ID' in csv_df.columns:
                csv_df['åˆ†é…ID'] = csv_df['åˆ†é…ID'].astype(str).replace('nan', '')
            if 'æ•´å‚™çµæœID' in csv_df.columns:
                csv_df['æ•´å‚™çµæœID'] = csv_df['æ•´å‚™çµæœID'].astype(str).replace('nan', '')
            csv_bytes = csv_df.to_csv(index=False).encode("shift_jis")
        
        dbx.files_upload(csv_bytes, path, mode=dropbox.files.WriteMode.overwrite)
        st.success("Dropboxã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except dropbox.exceptions.ApiError as e:
        st.error(f"Dropboxã¸ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        raise

# ==============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==============================

st.markdown("---")
st.subheader("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")
uploaded_file = st.file_uploader("id_management_file.csv ã‚’é¸æŠ", type=['csv'], key="csv_uploader")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'df' not in st.session_state:
    st.session_state.df = pd.DataFrame()
if 'csv_text_content' not in st.session_state:
    st.session_state.csv_text_content = None

df = st.session_state.df
error_info = None
csv_text_content = st.session_state.csv_text_content

if uploaded_file is not None:
    file_bytes = uploaded_file.read()
    df, error_info, csv_text_content = load_csv_from_bytes(file_bytes, encoding='shift_jis')
    
    if error_info:
        st.error(error_info)
    elif not df.empty:
        st.success(f"âœ… {uploaded_file.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆShift-JISï¼‰")
        st.session_state.df = df
        st.session_state.csv_text_content = csv_text_content
else:
    st.info("ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€Dropboxã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™")
    use_dropbox = st.checkbox("Dropboxã‹ã‚‰èª­ã¿è¾¼ã‚€", value=False)
    
    if use_dropbox:
        df, error_info, csv_text_content = load_csv_from_dropbox(DROPBOX_FILE_PATH)
        if error_info:
            st.error(error_info)
        elif not df.empty:
            st.session_state.df = df
            st.session_state.csv_text_content = csv_text_content

if df.empty:
    st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
    
    if error_info:
        st.markdown(error_info)
    
    st.markdown("---")
    st.subheader("ğŸ” ãƒ‘ã‚¹æ¢ç´¢æ©Ÿèƒ½")
    st.info("ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        explore_path = st.text_input("æ¢ç´¢ã™ã‚‹ãƒ‘ã‚¹ã‚’å…¥åŠ›ï¼ˆãƒ«ãƒ¼ãƒˆã¯ç©ºæ¬„ã¾ãŸã¯ /ï¼‰", value="", key="explore_path_input", placeholder="ç©ºæ¬„ã§ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€ä¾‹: /SARTRASã‚µãƒ¼ãƒãƒ¼")
    with col2:
        explore_button = st.button("ğŸ” ãƒ‘ã‚¹ã‚’æ¢ç´¢", type="primary", key="explore_button")
    
    if explore_button:
        normalized_explore_path = explore_path.strip()
        if normalized_explore_path == "" or normalized_explore_path == "/":
            normalized_explore_path = ""
            display_path = "ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºæ–‡å­—åˆ—ï¼‰"
        else:
            display_path = normalized_explore_path
            if not normalized_explore_path.startswith("/"):
                st.warning("âš ï¸ ãƒ‘ã‚¹ã¯ `/` ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
                normalized_explore_path = None
        
        if normalized_explore_path is not None:
            entries = explore_dropbox_path(normalized_explore_path)
            if entries is not None and len(entries) > 0:
                st.success(f"âœ… ãƒ‘ã‚¹ `{display_path}` ã®å†…å®¹:")
                
                folders = [e for e in entries if isinstance(e, dropbox.files.FolderMetadata)]
                files = [e for e in entries if isinstance(e, dropbox.files.FileMetadata)]
                
                if folders:
                    st.write("**ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€:**")
                    for entry in folders:
                        if normalized_explore_path == "":
                            full_path = f"/{entry.name}"
                        else:
                            full_path = f"{normalized_explore_path.rstrip('/')}/{entry.name}"
                        st.code(full_path, language=None)
                
                if files:
                    st.write("**ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«:**")
                    for entry in files:
                        if normalized_explore_path == "":
                            full_path = f"/{entry.name}"
                        else:
                            full_path = f"{normalized_explore_path.rstrip('/')}/{entry.name}"
                        file_size_kb = entry.size / 1024
                        st.write(f"`{full_path}` ({file_size_kb:.1f} KB)")
            elif entries is not None and len(entries) == 0:
                st.info(f"â„¹ï¸ ãƒ‘ã‚¹ `{display_path}` ã¯å­˜åœ¨ã—ã¾ã™ãŒã€ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã™ã€‚")
            else:
                st.error(f"âŒ ãƒ‘ã‚¹ `{display_path}` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                if normalized_explore_path != "":
                    st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºæ¬„ï¼‰ã‹ã‚‰æ¢ç´¢ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚")
else:
    st.markdown("---")
    st.subheader("ğŸ“‹ IDç®¡ç†ãƒ‡ãƒ¼ã‚¿ç·¨é›†")
    
    # å¹´åº¦è¿½åŠ æ©Ÿèƒ½
    st.markdown("#### â• å¹´åº¦è¿½åŠ ")
    col_add1, col_add2 = st.columns([2, 1])
    with col_add1:
        new_year = st.text_input("è¿½åŠ ã™ã‚‹å¹´åº¦ã‚’å…¥åŠ›", key="new_year_input", placeholder="ä¾‹: 2024")
    with col_add2:
        add_year_button = st.button("ğŸ“… å¹´åº¦ã‚’è¿½åŠ ", type="primary", use_container_width=True, key="add_year_button")
    
    if add_year_button:
        if new_year and new_year.strip():
            new_year_str = str(new_year.strip())
            # æ—¢å­˜ã®å¹´åº¦ã‚’ç¢ºèª
            existing_years = df['å¹´'].astype(str).tolist() if 'å¹´' in df.columns else []
            
            if new_year_str in existing_years:
                st.warning(f"âš ï¸ å¹´åº¦ã€Œ{new_year_str}ã€ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
            else:
                # æ–°ã—ã„å¹´åº¦ã®è¡Œã‚’è¿½åŠ ï¼ˆIDã¯æ–‡å­—åˆ—ã¨ã—ã¦åˆæœŸåŒ–ï¼‰
                new_row = pd.DataFrame({
                    'å¹´': [new_year_str],
                    'åˆ†é…PID': [''],
                    'åˆ†é…ID': [''],
                    'æ•´å‚™çµæœID': ['']
                }, dtype=str)
                df = pd.concat([df, new_row], ignore_index=True)
                
                # å¹´åº¦ã§ã‚½ãƒ¼ãƒˆï¼ˆæ•°å€¤ã¨ã—ã¦ã‚½ãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹ï¼‰
                try:
                    # æ•°å€¤ã¨ã—ã¦ã‚½ãƒ¼ãƒˆå¯èƒ½ã‹è©¦ã™
                    df['å¹´_æ•°å€¤'] = df['å¹´'].astype(str).str.extract('(\d+)')[0].astype(float, errors='ignore')
                    df = df.sort_values('å¹´_æ•°å€¤', na_position='last')
                    df = df.drop('å¹´_æ•°å€¤', axis=1)
                except:
                    # æ•°å€¤ã¨ã—ã¦ã‚½ãƒ¼ãƒˆã§ããªã„å ´åˆã¯æ–‡å­—åˆ—ã¨ã—ã¦ã‚½ãƒ¼ãƒˆ
                    df = df.sort_values('å¹´', na_position='last')
                
                df = df.reset_index(drop=True)
                # IDåˆ—ã‚’æ–‡å­—åˆ—å‹ã«ç¢ºå®Ÿã«å¤‰æ›
                if 'åˆ†é…PID' in df.columns:
                    df['åˆ†é…PID'] = df['åˆ†é…PID'].astype(str).replace('nan', '')
                if 'åˆ†é…ID' in df.columns:
                    df['åˆ†é…ID'] = df['åˆ†é…ID'].astype(str).replace('nan', '')
                if 'æ•´å‚™çµæœID' in df.columns:
                    df['æ•´å‚™çµæœID'] = df['æ•´å‚™çµæœID'].astype(str).replace('nan', '')
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
                st.session_state.df = df
                st.success(f"âœ… å¹´åº¦ã€Œ{new_year_str}ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
                st.rerun()
        else:
            st.warning("âš ï¸ å¹´åº¦ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    st.markdown("---")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰
    with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
        st.write("**DataFrameå‹æƒ…å ±:**")
        st.write(df.dtypes)
        st.write("**DataFrameå…ˆé ­5è¡Œ:**")
        st.write(df.head())
    
    # ç·¨é›†å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«
    try:
        edited_df = st.data_editor(
            df,
            use_container_width=True,
            num_rows="fixed",
            column_config={
                "å¹´": st.column_config.TextColumn("å¹´", disabled=True),
                "åˆ†é…PID": st.column_config.TextColumn("åˆ†é…PID"),
                "åˆ†é…ID": st.column_config.TextColumn("åˆ†é…ID"),
                "æ•´å‚™çµæœID": st.column_config.TextColumn("æ•´å‚™çµæœID")
            },
            key="data_editor"
        )
        # IDåˆ—ã‚’æ–‡å­—åˆ—å‹ã«ç¢ºå®Ÿã«å¤‰æ›ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã®çµæœã‚’æ–‡å­—åˆ—ã¨ã—ã¦ä¿æŒï¼‰
        if 'åˆ†é…PID' in edited_df.columns:
            edited_df['åˆ†é…PID'] = edited_df['åˆ†é…PID'].astype(str).replace('nan', '')
        if 'åˆ†é…ID' in edited_df.columns:
            edited_df['åˆ†é…ID'] = edited_df['åˆ†é…ID'].astype(str).replace('nan', '')
        if 'æ•´å‚™çµæœID' in edited_df.columns:
            edited_df['æ•´å‚™çµæœID'] = edited_df['æ•´å‚™çµæœID'].astype(str).replace('nan', '')
    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã‚¨ãƒ©ãƒ¼: {e}")
        st.info("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ç¢ºèªã—ã¦ã€DataFrame ã®å‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    
    st.markdown("---")
    
    # ãƒœã‚¿ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†èª­ã¿è¾¼ã¿
            if 'df' in st.session_state:
                del st.session_state.df
            if 'csv_text_content' in st.session_state:
                del st.session_state.csv_text_content
            st.rerun()
    
    with col2:
        if st.button("âœ… å¤‰æ›´ã‚’ä¿å­˜", type="primary", use_container_width=True):
            df = edited_df.copy()
            # IDåˆ—ã‚’æ–‡å­—åˆ—å‹ã«ç¢ºå®Ÿã«å¤‰æ›
            if 'åˆ†é…PID' in df.columns:
                df['åˆ†é…PID'] = df['åˆ†é…PID'].astype(str).replace('nan', '')
            if 'åˆ†é…ID' in df.columns:
                df['åˆ†é…ID'] = df['åˆ†é…ID'].astype(str).replace('nan', '')
            if 'æ•´å‚™çµæœID' in df.columns:
                df['æ•´å‚™çµæœID'] = df['æ•´å‚™çµæœID'].astype(str).replace('nan', '')
            st.session_state.df = df
            st.success("å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            st.rerun()
    
    with col3:
        if csv_text_content:
            lines = csv_text_content.split('\n')
            for i, row in edited_df.iterrows():
                if i + 1 < len(lines):
                    values = lines[i + 1].split(',')
                    if len(values) >= 4:
                        # IDã‚’æ–‡å­—åˆ—ã¨ã—ã¦ç¢ºå®Ÿã«æ‰±ã†
                        pid_str = str(row['åˆ†é…PID']) if pd.notna(row['åˆ†é…PID']) and str(row['åˆ†é…PID']) != 'nan' else ''
                        id_str = str(row['åˆ†é…ID']) if pd.notna(row['åˆ†é…ID']) and str(row['åˆ†é…ID']) != 'nan' else ''
                        result_id_str = str(row['æ•´å‚™çµæœID']) if pd.notna(row['æ•´å‚™çµæœID']) and str(row['æ•´å‚™çµæœID']) != 'nan' else ''
                        values[1] = pid_str
                        values[2] = id_str
                        values[3] = result_id_str
                        lines[i + 1] = ','.join(values)
            csv_content = '\n'.join(lines)
        else:
            # IDåˆ—ãŒæ–‡å­—åˆ—å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰CSVã«å¤‰æ›
            csv_df = edited_df.copy()
            if 'åˆ†é…PID' in csv_df.columns:
                csv_df['åˆ†é…PID'] = csv_df['åˆ†é…PID'].astype(str).replace('nan', '')
            if 'åˆ†é…ID' in csv_df.columns:
                csv_df['åˆ†é…ID'] = csv_df['åˆ†é…ID'].astype(str).replace('nan', '')
            if 'æ•´å‚™çµæœID' in csv_df.columns:
                csv_df['æ•´å‚™çµæœID'] = csv_df['æ•´å‚™çµæœID'].astype(str).replace('nan', '')
            csv_content = csv_df.to_csv(index=False)
        
        try:
            csv_bytes = csv_content.encode('shift_jis')
        except UnicodeEncodeError:
            csv_bytes = ('\uFEFF' + csv_content).encode('utf-8')
        
        st.download_button(
            label="ğŸ’¾ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_bytes,
            file_name="id_management_file.csv",
            mime="text/csv",
            use_container_width=True
        )