import streamlit as st
import pandas as pd
import requests
import dropbox
from io import BytesIO, StringIO
try:
    import chardet
    HAS_CHARDET = True
except ImportError:
    HAS_CHARDET = False

# ==============================
# Dropboxæ°¸ç¶šæ¥ç¶šå‡¦ç†
# ==============================
def get_dropbox_access_token():

    data = {
        "grant_type": "refresh_token",
        "refresh_token": st.secrets["DROPBOX_REFRESH_TOKEN"],
        "client_id": st.secrets["DROPBOX_APP_KEY"],
        "client_secret": st.secrets["DROPBOX_APP_SECRET"],
    }

    res = requests.post("https://api.dropboxapi.com/oauth2/token", data=data)
    res.raise_for_status()
    return res.json()["access_token"]

ACCESS_TOKEN = get_dropbox_access_token()
dbx = dropbox.Dropbox(ACCESS_TOKEN)

# ==============================
# è¨­å®š
# ==============================
DROPBOX_FILE_PATH = "/id_management_file.csv"

st.set_page_config(page_title="IDæ¡ç•ªç®¡ç†", layout="wide")
st.title("ğŸ“‹ IDæ¡ç•ªç®¡ç†")
st.caption("åˆ†é…PIDã€åˆ†é…IDã€æ•´å‚™çµæœIDã®å¹´åˆ¥æœ€çµ‚IDã‚’ç·¨é›†ã§ãã¾ã™")

# ==============================
# Dropboxãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¢ç´¢
# ==============================
def validate_path(path):
    """ãƒ‘ã‚¹ãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’æ¤œè¨¼"""
    if path is None:
        return False
    # ç©ºæ–‡å­—åˆ—ã¯ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã—ã¦æœ‰åŠ¹
    if path == "":
        return True
    if not isinstance(path, str):
        return False
    # ãƒ‘ã‚¹ã¯/ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼ˆç©ºæ–‡å­—åˆ—ä»¥å¤–ã®å ´åˆï¼‰
    if not path.startswith("/"):
        return False
    return True

def explore_dropbox_path(path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã‚’å–å¾—"""
    # ãƒ‘ã‚¹ã®æ¤œè¨¼
    if not validate_path(path):
        return None
    
    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’ä½¿ç”¨
    if path == "" or path == "/":
        normalized_path = ""
    else:
        # ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆæœ«å°¾ã®/ã‚’å‰Šé™¤ï¼‰
        normalized_path = path.rstrip("/")
    
    try:
        result = dbx.files_list_folder(normalized_path)
        return result.entries
    except dropbox.exceptions.BadInputError as e:
        # ç„¡åŠ¹ãªãƒ‘ã‚¹å½¢å¼
        return None
    except dropbox.exceptions.ApiError as e:
        # ãã®ä»–ã®APIã‚¨ãƒ©ãƒ¼ï¼ˆnot_foundãªã©ï¼‰
        return None
    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼
        return None

# ==============================
# CSVã®èª­ã¿è¾¼ã¿ï¼ˆShift-JISå¯¾å¿œï¼‰
# ==============================
def load_csv_from_bytes(data, encoding='shift_jis'):
    """ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰CSVã‚’èª­ã¿è¾¼ã‚€ï¼ˆShift-JISå¯¾å¿œï¼‰"""
    try:
        # æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒ‡ã‚³ãƒ¼ãƒ‰
        try:
            text_data = data.decode(encoding)
        except UnicodeDecodeError:
            # Shift-JISã§å¤±æ•—ã—ãŸå ´åˆã€UTF-8ã‚’è©¦è¡Œ
            try:
                text_data = data.decode('utf-8')
            except UnicodeDecodeError:
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡ºï¼ˆchardetãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                if HAS_CHARDET:
                    try:
                        detected = chardet.detect(data)
                        encoding = detected['encoding'] if detected['encoding'] else 'utf-8'
                        text_data = data.decode(encoding)
                    except:
                        # è‡ªå‹•æ¤œå‡ºã«å¤±æ•—ã—ãŸå ´åˆã¯UTF-8ã‚’è©¦è¡Œ
                        text_data = data.decode('utf-8', errors='ignore')
                else:
                    # chardetãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯UTF-8ã‚’è©¦è¡Œ
                    text_data = data.decode('utf-8', errors='ignore')
        
        # CSVã‚’èª­ã¿è¾¼ã‚€ï¼ˆAåˆ—=å¹´åº¦ã€Båˆ—=åˆ†é…PIDã€Cåˆ—=åˆ†é…IDã€Dåˆ—=æ•´å‚™çµæœIDï¼‰
        df = pd.read_csv(StringIO(text_data), header=0)
        
        # å¿…è¦ãªåˆ—ã®ã¿ã‚’æŠ½å‡ºï¼ˆAåˆ—=0, Båˆ—=1, Cåˆ—=2, Dåˆ—=3ï¼‰
        if len(df.columns) >= 4:
            # åˆ—åã‚’ãƒªãƒãƒ¼ãƒ 
            df_display = pd.DataFrame({
                'å¹´': df.iloc[:, 0],
                'åˆ†é…PID': df.iloc[:, 1],
                'åˆ†é…ID': df.iloc[:, 2],
                'æ•´å‚™çµæœID': df.iloc[:, 3]
            })
        else:
            df_display = df.copy()
        
        return df_display, None, text_data
    except pd.errors.EmptyDataError:
        return pd.DataFrame(), "âŒ **ã‚¨ãƒ©ãƒ¼:** ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™", None
    except pd.errors.ParserError as pe:
        return pd.DataFrame(), f"âŒ **ã‚¨ãƒ©ãƒ¼:** CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ\n**è©³ç´°:** {pe}", None
    except Exception as e:
        return pd.DataFrame(), f"âŒ **ã‚¨ãƒ©ãƒ¼:** ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ\n**è©³ç´°:** {e}", None

def load_csv_from_dropbox(path):
    """Dropboxã‹ã‚‰CSVã‚’èª­ã¿è¾¼ã‚€"""
    try:
        _, res = dbx.files_download(path)
        data = res.content
        df, error_info, text_data = load_csv_from_bytes(data)
        return df, error_info, text_data
    except dropbox.exceptions.ApiError as e:
        error_msg = str(e)
        error_info = []
        error_info.append("âŒ **ã‚¨ãƒ©ãƒ¼:** ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        error_info.append(f"**æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹:** `{path}`")
        
        # ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
        is_not_found = False
        if hasattr(e, 'error'):
            if hasattr(e.error, 'get_path'):
                path_error = e.error.get_path()
                if path_error and hasattr(path_error, 'get_not_found'):
                    is_not_found = True
        
        # æ–‡å­—åˆ—ã‹ã‚‰ã‚‚åˆ¤å®š
        if not is_not_found:
            error_str = str(e).lower()
            if "not_found" in error_str:
                is_not_found = True
        
        if is_not_found:
            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            path_parts = [p for p in path.split("/") if p]  # ç©ºæ–‡å­—åˆ—ã‚’é™¤å¤–
            if len(path_parts) > 0:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’é™¤ã„ãŸè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                if len(path_parts) > 1:
                    parent_path = "/" + "/".join(path_parts[:-1])
                else:
                    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                    parent_path = ""  # ç©ºæ–‡å­—åˆ—ãŒãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            else:
                parent_path = ""  # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
            if parent_path == "":
                error_info.append(f"\n**è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:** ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºæ–‡å­—åˆ—ï¼‰")
            else:
                error_info.append(f"\n**è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:** `{parent_path}`")
            
            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
            try:
                # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’ä½¿ç”¨
                explore_path = parent_path if parent_path != "" else ""
                entries = explore_dropbox_path(explore_path) if explore_path != "" else dbx.files_list_folder("").entries
                if entries:
                    available_files = []
                    available_folders = []
                    for entry in entries:
                        if isinstance(entry, dropbox.files.FileMetadata):
                            available_files.append(f"ğŸ“„ {entry.name}")
                        elif isinstance(entry, dropbox.files.FolderMetadata):
                            available_folders.append(f"ğŸ“ {entry.name}/")
                    
                    if available_files or available_folders:
                        error_info.append("\n**ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€:**")
                        for folder in available_folders:
                            error_info.append(f"  {folder}")
                        for file in available_files:
                            error_info.append(f"  {file}")
                else:
                    error_info.append("\nâš ï¸ è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            except Exception as explore_error:
                error_info.append(f"\nâš ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¢ç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {explore_error}")
        
        return pd.DataFrame(), "\n".join(error_info), None

# ==============================
# CSVã®ä¿å­˜
# ==============================
def save_csv_to_dropbox(df, path, original_text=None):
    """Dropboxã«CSVã‚’ä¿å­˜ï¼ˆå…ƒã®CSVæ§‹é€ ã‚’ä¿æŒï¼‰"""
    try:
        if original_text:
            # å…ƒã®CSVãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
            lines = original_text.split('\n')
            for i, row in df.iterrows():
                if i + 1 < len(lines):
                    values = lines[i + 1].split(',')
                    if len(values) >= 4:
                        values[1] = str(row['åˆ†é…PID']) if pd.notna(row['åˆ†é…PID']) else ''
                        values[2] = str(row['åˆ†é…ID']) if pd.notna(row['åˆ†é…ID']) else ''
                        values[3] = str(row['æ•´å‚™çµæœID']) if pd.notna(row['æ•´å‚™çµæœID']) else ''
                        lines[i + 1] = ','.join(values)
            csv_content = '\n'.join(lines)
            csv_bytes = csv_content.encode('shift_jis')
        else:
            # æ–°ã—ã„CSVã¨ã—ã¦ä¿å­˜
            csv_bytes = df.to_csv(index=False).encode("shift_jis")
        
        dbx.files_upload(csv_bytes, path, mode=dropbox.files.WriteMode.overwrite)
        st.success("Dropboxã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except dropbox.exceptions.ApiError as e:
        st.error(f"Dropboxã¸ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        raise

# ==============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==============================

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
st.markdown("---")
st.subheader("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")
uploaded_file = st.file_uploader("id_management_file.csv ã‚’é¸æŠ", type=['csv'], key="csv_uploader")

df = pd.DataFrame()
error_info = None
csv_text_content = None

if uploaded_file is not None:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    file_bytes = uploaded_file.read()
    df, error_info, csv_text_content = load_csv_from_bytes(file_bytes, encoding='shift_jis')
    
    if error_info:
        st.error(error_info)
    elif not df.empty:
        st.success(f"âœ… {uploaded_file.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆShift-JISï¼‰")
else:
    # Dropboxã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    st.info("ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€Dropboxã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™")
    use_dropbox = st.checkbox("Dropboxã‹ã‚‰èª­ã¿è¾¼ã‚€", value=False)
    
    if use_dropbox:
        df, error_info, csv_text_content = load_csv_from_dropbox(DROPBOX_FILE_PATH)
        if error_info:
            st.error(error_info)

if df.empty:
    st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
    
    if error_info:
        st.markdown(error_info)
    
    st.markdown("---")
    st.subheader("ğŸ” ãƒ‘ã‚¹æ¢ç´¢æ©Ÿèƒ½")
    st.info("ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€æ­£ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚")
    
    # ãƒ‘ã‚¹æ¢ç´¢ç”¨ã®UI
    col1, col2 = st.columns([3, 1])
    with col1:
        explore_path = st.text_input("æ¢ç´¢ã™ã‚‹ãƒ‘ã‚¹ã‚’å…¥åŠ›ï¼ˆãƒ«ãƒ¼ãƒˆã¯ç©ºæ¬„ã¾ãŸã¯ /ï¼‰", value="", key="explore_path_input", placeholder="ç©ºæ¬„ã§ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€ä¾‹: /SARTRASã‚µãƒ¼ãƒãƒ¼")
    with col2:
        explore_button = st.button("ğŸ” ãƒ‘ã‚¹ã‚’æ¢ç´¢", type="primary", key="explore_button")
    
    # ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã®ã¿æ¢ç´¢ã‚’å®Ÿè¡Œ
    if explore_button:
        # ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–ï¼ˆç©ºæ–‡å­—åˆ—ã¾ãŸã¯"/"ã¯ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
        normalized_explore_path = explore_path.strip()
        if normalized_explore_path == "" or normalized_explore_path == "/":
            normalized_explore_path = ""
            display_path = "ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºæ–‡å­—åˆ—ï¼‰"
        else:
            display_path = normalized_explore_path
            if not normalized_explore_path.startswith("/"):
                st.warning("âš ï¸ ãƒ‘ã‚¹ã¯ `/` ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
                normalized_explore_path = None
        
        if normalized_explore_path is not None:
            entries = explore_dropbox_path(normalized_explore_path)
            if entries is not None and len(entries) > 0:
                st.success(f"âœ… ãƒ‘ã‚¹ `{display_path}` ã®å†…å®¹:")
                
                # ãƒ•ã‚©ãƒ«ãƒ€ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†ã‘ã¦è¡¨ç¤º
                folders = [e for e in entries if isinstance(e, dropbox.files.FolderMetadata)]
                files = [e for e in entries if isinstance(e, dropbox.files.FileMetadata)]
                
                if folders:
                    st.write("**ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€:**")
                    for entry in folders:
                        if normalized_explore_path == "":
                            full_path = f"/{entry.name}"
                        else:
                            full_path = f"{normalized_explore_path.rstrip('/')}/{entry.name}"
                        st.code(full_path, language=None)
                
                if files:
                    st.write("**ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«:**")
                    for entry in files:
                        if normalized_explore_path == "":
                            full_path = f"/{entry.name}"
                        else:
                            full_path = f"{normalized_explore_path.rstrip('/')}/{entry.name}"
                        file_size_kb = entry.size / 1024
                        st.write(f"`{full_path}` ({file_size_kb:.1f} KB)")
            elif entries is not None and len(entries) == 0:
                st.info(f"â„¹ï¸ ãƒ‘ã‚¹ `{display_path}` ã¯å­˜åœ¨ã—ã¾ã™ãŒã€ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã™ã€‚")
            else:
                st.error(f"âŒ ãƒ‘ã‚¹ `{display_path}` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                if normalized_explore_path != "":
                    st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆç©ºæ¬„ï¼‰ã‹ã‚‰æ¢ç´¢ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚")
else:
    st.markdown("---")
    st.subheader("ğŸ“‹ IDç®¡ç†ãƒ‡ãƒ¼ã‚¿ç·¨é›†")
    
    # ç·¨é›†å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«
    edited_df = st.data_editor(
        df,
        use_container_width=True,
        num_rows="fixed",
        column_config={
            "å¹´": st.column_config.TextColumn("å¹´", disabled=True),
            "åˆ†é…PID": st.column_config.TextColumn("åˆ†é…PID"),
            "åˆ†é…ID": st.column_config.TextColumn("åˆ†é…ID"),
            "æ•´å‚™çµæœID": st.column_config.TextColumn("æ•´å‚™çµæœID")
        },
        key="data_editor"
    )
    
    st.markdown("---")
    
    # ãƒœã‚¿ãƒ³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
            st.rerun()
    
    with col2:
        if st.button("âœ… å¤‰æ›´ã‚’ä¿å­˜", type="primary", use_container_width=True):
            # ç·¨é›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°
            df = edited_df.copy()
            st.success("å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            st.rerun()
    
    with col3:
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        if csv_text_content:
            lines = csv_text_content.split('\n')
            for i, row in edited_df.iterrows():
                if i + 1 < len(lines):
                    values = lines[i + 1].split(',')
                    if len(values) >= 4:
                        values[1] = str(row['åˆ†é…PID']) if pd.notna(row['åˆ†é…PID']) else ''
                        values[2] = str(row['åˆ†é…ID']) if pd.notna(row['åˆ†é…ID']) else ''
                        values[3] = str(row['æ•´å‚™çµæœID']) if pd.notna(row['æ•´å‚™çµæœID']) else ''
                        lines[i + 1] = ','.join(values)
            csv_content = '\n'.join(lines)
        else:
            csv_content = edited_df.to_csv(index=False)
        
        # Shift-JISã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        try:
            csv_bytes = csv_content.encode('shift_jis')
        except UnicodeEncodeError:
            # Shift-JISã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ããªã„å ´åˆã¯UTF-8 BOMä»˜ã
            csv_bytes = ('\uFEFF' + csv_content).encode('utf-8')
        
        st.download_button(
            label="ğŸ’¾ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_bytes,
            file_name="id_management_file.csv",
            mime="text/csv",
            use_container_width=True
        )
